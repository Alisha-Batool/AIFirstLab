# -*- coding: utf-8 -*-
"""Android.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DRSGjerArh6pK3fdBiV1lNxNiLLQQbBd
"""

import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/AILabWork/Android_Malware.csv')
df.head()

# === üìä DATA INSPECTION SECTION ===
print("===== Dataset Overview =====")
print("Shape (Rows, Columns):", df.shape)
print("Total Elements:", df.size)
print("\n===== Column Names =====")
print(list(df.columns))

print("\n===== Null Values per Column =====")
print(df.isnull().sum())

print("\nAny Null Values Present?:", df.isnull().values.any())

print("\n===== Duplicate Rows =====")
print("Total Duplicates:", df.duplicated().sum())

print("\n===== Duplicate Columns (if any) =====")
print(df.columns[df.columns.duplicated()])

print("\n===== Data Types of Each Column =====")
print(df.dtypes)

print("\n===== Statistical Summary (Numeric Columns) =====")
print(df.describe())

import matplotlib

# ==========================
# üìä DATA VISUALIZATION CODE
# ==========================

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# === 0Ô∏è‚É£ LOAD DATASET ===
data = pd.read_csv('/content/drive/MyDrive/AILabWork/Android_Malware.csv')

# === 1Ô∏è‚É£ BASIC INFO ===
print("‚úÖ Dataset Loaded Successfully!\n")
print("Shape of Dataset:", data.shape)
print("\nColumns:\n", data.columns)
print("\nNull Values:\n", data.isnull().sum())
print("\nDuplicate Rows:", data.duplicated().sum())

# === 2Ô∏è‚É£ PIE CHART (for 'label' or 'class' columns) ===
if 'label' in data.columns or 'class' in data.columns:
    col = 'label' if 'label' in data.columns else 'class'
    data[col].value_counts().plot(
        kind='pie',
        autopct='%1.1f%%',
        colors=plt.cm.Paired.colors,
        startangle=90,
        shadow=True
    )
    plt.title(f'Distribution of {col}')
    plt.ylabel('')
    plt.show()
else:
    print("‚ö†Ô∏è No 'label' or 'class' column found for pie chart.\n")

# === 3Ô∏è‚É£ HISTOGRAM for all numerical columns ===
data.hist(figsize=(12, 10), bins=20, color='skyblue', edgecolor='black')
plt.suptitle('Histogram of Numerical Features', fontsize=14)
plt.show()

# === 4Ô∏è‚É£ CORRELATION HEATMAP (only for numeric columns) ===
plt.figure(figsize=(10, 8))
numeric_data = data.select_dtypes(include=['int64', 'float64'])

if not numeric_data.empty:
    sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm')
    plt.title('Feature Correlation Heatmap (Numeric Only)')
    plt.show()
else:
    print("‚ö†Ô∏è No numeric columns found for correlation heatmap.\n")

# === 5Ô∏è‚É£ BAR CHART (Top 10 Categories for each object column) ===
for col in data.select_dtypes(include=['object']).columns:
    plt.figure(figsize=(8, 4))
    data[col].value_counts().head(10).plot(kind='bar', color='teal')
    plt.title(f'Top 10 Categories in {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.show()

print("\nüéâ Visualization Completed Successfully!")

from google.colab import drive
drive.mount('/content/drive')

"""# Machine Learning Models
| No. | Model                        | Type          | Description                                             | Common Use Case                            |
| --- | ---------------------------- | ------------- | ------------------------------------------------------- | ------------------------------------------ |
| 1   | Linear Regression            | Supervised    | Predicts continuous values using a linear relationship. | Predicting house prices, sales forecasting |
| 2   | Logistic Regression          | Supervised    | Estimates probability for binary outcomes.              | Spam detection, medical diagnosis          |
| 3   | Decision Tree                | Supervised    | Tree-structured model for decision making.              | Classification tasks, credit scoring       |
| 4   | Random Forest                | Ensemble      | Combines multiple decision trees for better accuracy.   | Fraud detection, feature importance        |
| 5   | Support Vector Machine (SVM) | Supervised    | Maximizes the margin between classes.                   | Text classification, image classification  |
| 6   | K-Nearest Neighbors (KNN)    | Supervised    | Classifies based on proximity to nearest data points.   | Pattern recognition, recommender systems   |
| 7   | Naive Bayes                  | Probabilistic | Uses Bayes‚Äô theorem for classification.                 | Spam filtering, sentiment analysis         |
# Deep Learning Models
| No. | Model                              | Type            | Description                                           | Common Use Case                            |
| --- | ---------------------------------- | --------------- | ----------------------------------------------------- | ------------------------------------------ |
| 8   | Artificial Neural Network (ANN)    | Feedforward     | Basic neural network with fully connected layers.     | Regression/classification                  |
| 9   | Convolutional Neural Network (CNN) | Deep            | Extracts spatial features using convolutional layers. | Image recognition                          |
| 10  | Recurrent Neural Network (RNN)     | Sequential      | Handles sequential/time-series data.                  | Speech recognition, time series prediction |
| 11  | Long Short-Term Memory (LSTM)      | Sequential      | Improved RNN with long-term memory.                   | Text generation, stock forecasting         |
| 12  | Autoencoder                        | Unsupervised    | Learns efficient data encodings for reconstruction.   | Anomaly detection, denoising               |
| 13  | Transformer                        | Attention-based | Uses self-attention to model context.                 | Translation, text understanding            |
# Computer Vision Models
| No. | Model                     | Type                | Description                                         | Common Use Case                      |
| --- | ------------------------- | ------------------- | --------------------------------------------------- | ------------------------------------ |
| 14  | LeNet-5                   | CNN                 | Early CNN for digit recognition.                    | MNIST digit classification           |
| 15  | AlexNet                   | CNN                 | Deep CNN that popularized deep learning in vision.  | Image classification                 |
| 16  | VGG16/VGG19               | CNN                 | Uses deep stacks of 3√ó3 convolutions.               | Feature extraction, object detection |
| 17  | ResNet                    | CNN (Residual)      | Introduces skip connections for very deep networks. | Image classification                 |
| 18  | Inception (GoogLeNet)     | CNN                 | Uses multi-scale convolutions in one layer.         | Object recognition                   |
| 19  | YOLO (You Only Look Once) | Real-time detection | Real-time object detection.                         | Surveillance, autonomous driving     |
# Natural Language Processing (NLP) Models
| No. | Model                                  | Type        | Description                                     | Common Use Case                  |
| --- | -------------------------------------- | ----------- | ----------------------------------------------- | -------------------------------- |
| 20  | Bag of Words (BoW)                     | Statistical | Represents text as word counts.                 | Text classification              |
| 21  | Word2Vec                               | Embedding   | Maps words to dense vector space.               | Semantic similarity              |
| 22  | GloVe                                  | Embedding   | Global vectors trained on co-occurrence matrix. | Text clustering, semantic search |
| 23  | BERT                                   | Transformer | Understands context in both directions.         | Q&A, text classification         |
| 24  | GPT                                    | Transformer | Generates coherent, human-like text.            | Text generation, chatbots        |
| 25  | T5 (Text-to-Text Transfer Transformer) | Transformer | Treats every NLP task as text-to-text.          | Summarization, translation       |

"""